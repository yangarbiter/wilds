{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaaea907-591f-4d6c-b393-7451b653a5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path = [\"./\", \"../examples/\", \"../\", ] + sys.path\n",
    "#sys.path.append(\"../\")\n",
    "#sys.path.append(\"../examples/\")\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "from torchmetrics import CalibrationError\n",
    "import joblib\n",
    "\n",
    "from models.initializer import initialize_torchvision_model, initialize_model\n",
    "from transforms import initialize_transform\n",
    "from utils import get_config\n",
    "import wilds\n",
    "from wilds.common.grouper import CombinatorialGrouper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c5e1d0f-29bf-4185-aa29-946433879dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_loader(config):\n",
    "    full_dataset = wilds.get_dataset(\n",
    "        dataset=config.dataset,\n",
    "        version=config.version,\n",
    "        root_dir=config.root_dir,\n",
    "        download=True,\n",
    "        split_scheme=config.split_scheme,\n",
    "        **config.dataset_kwargs)\n",
    "    eval_transform = initialize_transform(\n",
    "        transform_name=config.transform,\n",
    "        config=config,\n",
    "        dataset=full_dataset,\n",
    "        is_training=False)\n",
    "    train_grouper = CombinatorialGrouper(\n",
    "        dataset=full_dataset,\n",
    "        groupby_fields=config.groupby_fields)\n",
    "    \n",
    "    trn_dset = full_dataset.get_subset(\n",
    "        \"train\",\n",
    "        train_grouper=train_grouper,\n",
    "        frac=config.frac,\n",
    "        transform=eval_transform,\n",
    "        subsample_to_minority=config.subsample)\n",
    "    trn_loader = DataLoader(\n",
    "        trn_dset,\n",
    "        shuffle=False, # Do not shuffle eval datasets\n",
    "        sampler=None,\n",
    "        collate_fn=trn_dset.collate,\n",
    "        batch_size=config.batch_size,\n",
    "        **config.loader_kwargs)\n",
    "    tst_dset = full_dataset.get_subset(\n",
    "        \"test\",\n",
    "        train_grouper=train_grouper,\n",
    "        frac=config.frac,\n",
    "        transform=eval_transform,\n",
    "        subsample_to_minority=config.subsample)\n",
    "    tst_loader = DataLoader(\n",
    "        tst_dset,\n",
    "        shuffle=False, # Do not shuffle eval datasets\n",
    "        sampler=None,\n",
    "        collate_fn=tst_dset.collate,\n",
    "        batch_size=config.batch_size,\n",
    "        **config.loader_kwargs)\n",
    "    return trn_loader, tst_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1803a832-6be0-4e43-8e34-e499eb8b3994",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"celebA\"\n",
    "config = get_config(dataset, \"ERM\", \"../data\")\n",
    "config.batch_size = 32\n",
    "trn_loader, tst_loader = get_dataset_loader(config)\n",
    "\n",
    "params = [{\n",
    "    'name': \"ERM\",\n",
    "    \"arch\": \"resnet50\",\n",
    "    'model_path': \"../logs/celebA/erm-resnet50/celebA_seed:0_epoch:last_model.pth\",\n",
    "    'pred_dir': \"../logs/celebA/erm-resnet50/\",\n",
    "}]\n",
    "params += [{\n",
    "    'name': \"ERM DPSGD\",\n",
    "    \"arch\": \"dp_resnet50\",\n",
    "    'model_path': f\"../logs/celebA/erm-dp_resnet50-lr1e-3-dpsgd_1e-5_{gamma}_1.0_0.0001/celebA_seed:0_epoch:last_model.pth\",\n",
    "    'pred_dir': f\"../logs/celebA/erm-dp_resnet50-lr1e-3-dpsgd_1e-5_{gamma}_1.0_0.0001/\",\n",
    "} for gamma in [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22464b3e-e6a7-42fc-bdd5-aa85fbe3326a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a34547602be845adb280b4721893dd89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5087 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "472f16bf2983483bbdb748400f772991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/624 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf3118f7c16c4e5396c38a221d038c34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5087 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d00a80b42aad4fc7a18758971f343fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/624 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "\n",
    "for param in params:\n",
    "    name, arch, model_path, pred_dir = param['name'], param['arch'], param['model_path'], param['pred_dir']\n",
    "\n",
    "    if os.path.exists(os.path.join(pred_dir, \"preds.pkl\")):\n",
    "        continue\n",
    "        \n",
    "    d_out = 2\n",
    "    model = initialize_torchvision_model(arch, d_out)\n",
    "    res = torch.load(model_path)['algorithm']\n",
    "    state_dict = {}\n",
    "    for k, v in res.items():\n",
    "        if \"dp\" in arch:\n",
    "            state_dict[k.replace(\"model._module.\", \"\")] = v\n",
    "        else:\n",
    "            state_dict[k.replace(\"model.\", \"\")] = v\n",
    "    model.load_state_dict(state_dict)\n",
    "    _ = model.to(device)\n",
    "    \n",
    "    ret = {\"trn\": [], \"tst\": [], \"trny\": [], \"tsty\": []}\n",
    "    for x, y, _ in tqdm(trn_loader):\n",
    "        ret[\"trn\"].append(model(x.to(device)).detach().cpu())\n",
    "        ret[\"trny\"].append(y.detach().cpu())\n",
    "    ret[\"trn\"] = torch.cat(ret[\"trn\"], dim=0)\n",
    "    for x, y, _ in tqdm(tst_loader):\n",
    "        ret[\"tst\"].append(model(x.to(device)).detach().cpu())\n",
    "        ret[\"tsty\"].append(y.detach().cpu())\n",
    "    ret[\"tst\"] = torch.cat(ret[\"tst\"], dim=0)\n",
    "    \n",
    "    joblib.dump(ret, os.path.join(pred_dir, \"preds.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5772108-8952-427b-a019-361101932304",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810e374b-0966-4eb1-bfe5-3a6a6485b4cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40a8533-d51d-4bab-8e3f-8510cbaa6fb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02a21c3e-287c-4309-b408-bfc2b9c9d7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "992053a5-42bb-4865-aac2-a1eb3da40fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"celebA\"\n",
    "config = get_config(dataset, \"ERM\", \"../data\")\n",
    "loader = get_dataset_loader(config)\n",
    "\n",
    "params = [{\n",
    "    'name': \"ERM\",\n",
    "    \"arch\": \"resnet50\",\n",
    "    'model_path': \"../logs/celebA/erm/celebA_seed:0_epoch:last_model.pth\",\n",
    "}, {\n",
    "    'name': \"DRO\",\n",
    "    \"arch\": \"resnet50\",\n",
    "    'model_path': \"../logs/celebA/groupDRO/celebA_seed:0_epoch:last_model.pth\",\n",
    "}, {\n",
    "    'name': \"DRO wd\",\n",
    "    \"arch\": \"resnet50\",\n",
    "    'model_path': \"../logs/celebA/groupDRO_wd0.1/celebA_seed:0_epoch:last_model.pth\",\n",
    "}, {\n",
    "    'name': \"ERM IW\",\n",
    "    \"arch\": \"resnet18\",\n",
    "    'model_path': \"../logs/celebA/erm_reweight/celebA_seed:0_epoch:last_model.pth\",\n",
    "}, {\n",
    "    'name': \"ERM DPSGD\",\n",
    "    \"arch\": \"dp_resnet18\",\n",
    "    'model_path': \"../logs/celebA/erm-dp_resnet18-dpsgd_1e-5_1.0_0.1_0.0001/celebA_seed:0_epoch:last_model.pth\",\n",
    "}, {\n",
    "    'name': \"ERM IW DPSGD\",\n",
    "    \"arch\": \"dp_resnet18\",\n",
    "    'model_path': \"../logs/celebA/iwerm-dp_resnet18-dpsgd_1e-5_1.0_1.0_0.0001/celebA_seed:0_epoch:last_model.pth\",\n",
    "},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36fa59e-f1a1-4064-b93d-a62c1f5aa2fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93ef3928-ec51-4c30-87cc-7af3c5ab1e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4d210a436e746deaaa2f180eb0f1414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70632c9de98643c4a8ccc5ce5eda20ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b58531f24a02468182be76c2f2b06e48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7328ac440b6a474795414e67ea308cb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1efbc2b75675458e84b6fb448bc1a5a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4516d0d7267041b0aeab6b16ae37f05f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "\n",
    "for param in params:\n",
    "    name, arch, model_path = param['name'], param['arch'], param['model_path']\n",
    "\n",
    "    d_out = 2\n",
    "    model = initialize_torchvision_model(arch, d_out)\n",
    "    res = torch.load(model_path)['algorithm']\n",
    "    state_dict = {}\n",
    "    for k, v in res.items():\n",
    "        if \"dp\" in arch:\n",
    "            state_dict[k.replace(\"model._module.\", \"\")] = v\n",
    "        else:\n",
    "            state_dict[k.replace(\"model.\", \"\")] = v\n",
    "    model.load_state_dict(state_dict)\n",
    "    _ = model.to(device)\n",
    "    \n",
    "    proba, truths = [], []\n",
    "    for x, y, _ in tqdm(loader):\n",
    "        proba.append(torch.nn.Softmax(dim=1)(model(x.to(device))).detach().cpu())\n",
    "        truths.append(y)\n",
    "    proba = torch.cat(proba, dim=0)\n",
    "    truths = torch.cat(truths)\n",
    "    \n",
    "    error = CalibrationError()\n",
    "    error(proba, truths)\n",
    "    results[(dataset, name)] = error.compute().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "919cc6e7-aeff-46af-9e80-4f2329ccb49f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(celebA, ERM)</th>\n",
       "      <td>0.041986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(celebA, DRO wd)</th>\n",
       "      <td>0.366747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(celebA, ERM IW)</th>\n",
       "      <td>0.101050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(celebA, ERM DPSGD)</th>\n",
       "      <td>0.054780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(celebA, ERM IW DPSGD)</th>\n",
       "      <td>0.055586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               0\n",
       "(celebA, ERM)           0.041986\n",
       "(celebA, DRO wd)        0.366747\n",
       "(celebA, ERM IW)        0.101050\n",
       "(celebA, ERM DPSGD)     0.054780\n",
       "(celebA, ERM IW DPSGD)  0.055586"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(results, orient=\"index\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29a188e4-5679-417e-81bc-1df9bd3d89f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('celebA', 'ERM'): 0.04198582097887993,\n",
       " ('celebA', 'DRO wd'): 0.36674678325653076,\n",
       " ('celebA', 'ERM IW'): 0.10104991495609283,\n",
       " ('celebA', 'ERM DPSGD'): 0.05478046089410782,\n",
       " ('celebA', 'ERM IW DPSGD'): 0.0555860698223114}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2e54f39-0255-415f-b2bc-70e04eaec613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset to ../data/UTKFace_v1.0...\n",
      "You can also download the dataset manually at https://wilds.stanford.edu/downloads.\n",
      "Downloading  to ../data/UTKFace_v1.0/archive.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c259c5dac59426e9e6bc42931028b34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0Byte [00:00, ?Byte/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "../data/UTKFace_v1.0/archive.tar.gz may be corrupted. Please try deleting it and rerunning this command.\n",
      "\n",
      "Exception:  unknown url type: ''\n",
      "problem with:  ../data/UTKFace_v1.0/39_1_20170116174525125.jpg.chip.jpg\n",
      "problem with:  ../data/UTKFace_v1.0/61_1_20170109142408075.jpg.chip.jpg\n",
      "problem with:  ../data/UTKFace_v1.0/61_1_20170109150557335.jpg.chip.jpg\n"
     ]
    }
   ],
   "source": [
    "dataset = \"utkface\"\n",
    "config = get_config(dataset, \"ERM\", \"../data\")\n",
    "config.download = True\n",
    "loader = get_dataset_loader(config)\n",
    "\n",
    "params = [{\n",
    "    'name': \"ERM\",\n",
    "    \"arch\": \"resnet50\",\n",
    "    'model_path': \"../logs/utkface/erm-resnet50/UTKFace_seed:0_epoch:last_model.pth\",\n",
    "}, {\n",
    "    'name': \"DRO\",\n",
    "    \"arch\": \"resnet50\",\n",
    "    'model_path': \"../logs/utkface/groupDRO-resnet50/UTKFace_seed:0_epoch:last_model.pth\",\n",
    "}, {\n",
    "    'name': \"DRO wd\",\n",
    "    \"arch\": \"resnet50\",\n",
    "    'model_path': \"../logs/utkface/groupDRO-resnet50_wd0.1/UTKFace_seed:0_epoch:last_model.pth\",\n",
    "}, {\n",
    "    'name': \"ERM IW\",\n",
    "    \"arch\": \"resnet50\",\n",
    "    'model_path': \"../logs/utkface/erm_reweight-resnet50/UTKFace_seed:0_epoch:last_model.pth\",\n",
    "#}, {\n",
    "#    'name': \"ERM IW DPSGD\",\n",
    "#    \"arch\": \"dp_bert-base-uncased\",\n",
    "#    'model_path': \"../logs/celebA/iwerm-dp_resnet18-dpsgd_1e-5_1.0_1.0_0.0001/celebA_seed:0_epoch:last_model.pth\",\n",
    "}, {\n",
    "    'name': \"ERM DPSGD\",\n",
    "    \"arch\": \"dp_resnet50\",\n",
    "    'model_path': \"../logs/utkface/erm-dp_resnet50-dpsgd_1e-5_0.5_1.0_0.0005/UTKFace_seed:0_epoch:last_model.pth\",\n",
    "}, {\n",
    "    'name': \"ERM IW DPSGD\",\n",
    "    \"arch\": \"dp_resnet50\",\n",
    "    'model_path': \"../logs/utkface/weightederm-dp_resnet50-dpsgd_1e-5_0.01_1.0_0.001/UTKFace_seed:0_epoch:last_model.pth\",\n",
    "}, {\n",
    "    'name': \"DRO DPSGD\",\n",
    "    \"arch\": \"dp_resnet50\",\n",
    "    'model_path': \"../logs/utkface/groupdro-dp_resnet50-dpsgd_1e-5_0.01_1.0_0.001/UTKFace_seed:0_epoch:last_model.pth\",\n",
    "},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78356b26-b48e-4c2e-ba15-35bf96705283",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62b39e1b964b4be0b4633193c581668a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e22a914c62ae4e35a37b719166c00f3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac5dfadb69a64336b42e8c4588b08b97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcc678c4ec97479abce59ed40e6615bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ac674a673604e4291c2ad22d3b451aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a8953e43f82401dacc0344302180c7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fe55e7937024b7da2f55b2c3854042e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "\n",
    "for param in params:\n",
    "    name, arch, model_path = param['name'], param['arch'], param['model_path']\n",
    "    config.model = arch\n",
    "    \n",
    "    \n",
    "    d_out = 2\n",
    "    model = initialize_model(config, d_out)\n",
    "    res = torch.load(model_path)['algorithm']\n",
    "    state_dict = {}\n",
    "    for k, v in res.items():\n",
    "        if \"dp\" in arch:\n",
    "            state_dict[k.replace(\"model._module.\", \"\")] = v\n",
    "        else:\n",
    "            state_dict[k.replace(\"model.\", \"\")] = v\n",
    "    model.load_state_dict(state_dict)\n",
    "    _ = model.to(device)\n",
    "    \n",
    "    proba, truths = [], []\n",
    "    for x, y, _ in tqdm(loader):\n",
    "        proba.append(torch.nn.Softmax(dim=1)(model(x.to(device))).detach().cpu())\n",
    "        truths.append(y)\n",
    "    proba = torch.cat(proba, dim=0)\n",
    "    truths = torch.cat(truths)\n",
    "    \n",
    "    error = CalibrationError()\n",
    "    error(proba, truths)\n",
    "    results[(dataset, name)] = error.compute().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05abd40d-ae31-46b3-b284-f5e832295b19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37b0c099-cd71-4b2b-b3da-ec71df44988d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"civilcomments\"\n",
    "config = get_config(dataset, \"ERM\", \"../data\")\n",
    "\n",
    "params = [{\n",
    "    'name': \"ERM\",\n",
    "    \"arch\": \"head_bert-base-uncased\",\n",
    "    'model_path': \"../logs/civilcomments/erm-head_bert-base-uncased/civilcomments_seed:0_epoch:last_model.pth\",\n",
    "}, {\n",
    "    'name': \"DRO\",\n",
    "    \"arch\": \"head_bert-base-uncased\",\n",
    "    'model_path': \"../logs/civilcomments/groupDRO-head_bert-base-uncased/civilcomments_seed:0_epoch:last_model.pth\",\n",
    "}, {\n",
    "    'name': \"DRO wd\",\n",
    "    \"arch\": \"head_bert-base-uncased\",\n",
    "    'model_path': \"../logs/civilcomments/groupDRO-head_bert-base-uncased_wd1.0/civilcomments_seed:0_epoch:last_model.pth\",\n",
    "}, {\n",
    "    'name': \"ERM IW\",\n",
    "    \"arch\": \"head_bert-base-uncased\",\n",
    "    'model_path': \"../logs/civilcomments/erm_reweight-head_bert-base-uncased/civilcomments_seed:0_epoch:last_model.pth\",\n",
    "#}, {\n",
    "#    'name': \"ERM IW DPSGD\",\n",
    "#    \"arch\": \"dp_bert-base-uncased\",\n",
    "#    'model_path': \"../logs/celebA/iwerm-dp_resnet18-dpsgd_1e-5_1.0_1.0_0.0001/celebA_seed:0_epoch:last_model.pth\",\n",
    "}, {\n",
    "    'name': \"ERM IW DPSGD\",\n",
    "    \"arch\": \"dp_bert-base-uncased\",\n",
    "    'model_path': \"../logs/civilcomments/weightederm-dp_bert-base-uncased-dpsgd_1e-5_0.5_1.0_0.0001/civilcomments_seed:0_epoch:last_model.pth\",\n",
    "}, {\n",
    "    'name': \"IWERM DPSGD\",\n",
    "    \"arch\": \"dp_bert-base-uncased\",\n",
    "    'model_path': \"../logs/civilcomments/iwerm-dp_bert-base-uncased-lr1e-5_dpAdamW_1e-5_0.001_1.0_0.0002/civilcomments_seed:0_epoch:last_model.pth\",\n",
    "}, {\n",
    "    'name': \"DRO DPSGD\",\n",
    "    \"arch\": \"dp_bert-base-uncased\",\n",
    "    'model_path': \"../logs/civilcomments/groupdro-dp_bert-base-uncased-lr1e-5_dpAdamW_1e-5_0.001_1.0_0.0002/civilcomments_seed:0_epoch:last_model.pth\",\n",
    "},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf9f8e46-e6ef-4204-a694-6b9aff525e7c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertClassifier: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertClassifier from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertClassifier from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10b2f15a4fa44970917291af202a763c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertClassifier: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertClassifier from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertClassifier from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78c64dbbf0e047148080ebeefc149514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertClassifier: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertClassifier from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertClassifier from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1befc949f1dc48c599f620c4972d0e36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertClassifier: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertClassifier from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertClassifier from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "541a729c85a94cbd8191af25dfcbae1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertClassifier: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertClassifier from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertClassifier from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67c73a17947040e8b5f757d2ffd19f85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertClassifier: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertClassifier from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertClassifier from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7dde36f932e428bbf1bbe699ba1ef74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertClassifier: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertClassifier from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertClassifier from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aae13aa3bece49608d8833fa976b8043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "\n",
    "for param in params:\n",
    "    name, arch, model_path = param['name'], param['arch'], param['model_path']\n",
    "    config.model = arch\n",
    "    loader = get_dataset_loader(config)\n",
    "    \n",
    "    d_out = 2\n",
    "    model = initialize_model(config, d_out)\n",
    "    res = torch.load(model_path)['algorithm']\n",
    "    state_dict = {}\n",
    "    for k, v in res.items():\n",
    "        if \"dp\" in arch:\n",
    "            state_dict[k.replace(\"model._module.\", \"\")] = v\n",
    "        else:\n",
    "            state_dict[k.replace(\"model.\", \"\")] = v\n",
    "    model.load_state_dict(state_dict)\n",
    "    _ = model.to(device)\n",
    "    \n",
    "    proba, truths = [], []\n",
    "    counts = 0\n",
    "    for x, y, _ in tqdm(loader):\n",
    "        proba.append(torch.nn.Softmax(dim=1)(model(x.to(device))).detach().cpu())\n",
    "        truths.append(y)\n",
    "        counts += 1\n",
    "        if counts == 1000:\n",
    "            break\n",
    "    proba = torch.cat(proba, dim=0)\n",
    "    truths = torch.cat(truths)\n",
    "    \n",
    "    error = CalibrationError()\n",
    "    error(proba, truths)\n",
    "    results[(dataset, name)] = error.compute().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04eeaa2a-e97c-4002-bcc2-dcc0ee9b38ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">utkface</th>\n",
       "      <th>ERM</th>\n",
       "      <td>0.020405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DRO</th>\n",
       "      <td>0.060203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DRO wd</th>\n",
       "      <td>0.068113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERM IW</th>\n",
       "      <td>0.016250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERM DPSGD</th>\n",
       "      <td>0.026500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERM IW DPSGD</th>\n",
       "      <td>0.060824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DRO DPSGD</th>\n",
       "      <td>0.068309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">civilcomments</th>\n",
       "      <th>ERM</th>\n",
       "      <td>0.037293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DRO</th>\n",
       "      <td>0.069121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DRO wd</th>\n",
       "      <td>0.062794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERM IW</th>\n",
       "      <td>0.065083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERM IW DPSGD</th>\n",
       "      <td>0.151231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IWERM DPSGD</th>\n",
       "      <td>0.241695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DRO DPSGD</th>\n",
       "      <td>0.093338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">celebA</th>\n",
       "      <th>ERM</th>\n",
       "      <td>0.041986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DRO</th>\n",
       "      <td>0.103176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DRO wd</th>\n",
       "      <td>0.085320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERM IW</th>\n",
       "      <td>0.101050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERM DPSGD</th>\n",
       "      <td>0.054780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERM IW DPSGD</th>\n",
       "      <td>0.055586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   0\n",
       "utkface       ERM           0.020405\n",
       "              DRO           0.060203\n",
       "              DRO wd        0.068113\n",
       "              ERM IW        0.016250\n",
       "              ERM DPSGD     0.026500\n",
       "              ERM IW DPSGD  0.060824\n",
       "              DRO DPSGD     0.068309\n",
       "civilcomments ERM           0.037293\n",
       "              DRO           0.069121\n",
       "              DRO wd        0.062794\n",
       "              ERM IW        0.065083\n",
       "              ERM IW DPSGD  0.151231\n",
       "              IWERM DPSGD   0.241695\n",
       "              DRO DPSGD     0.093338\n",
       "celebA        ERM           0.041986\n",
       "              DRO           0.103176\n",
       "              DRO wd        0.085320\n",
       "              ERM IW        0.101050\n",
       "              ERM DPSGD     0.054780\n",
       "              ERM IW DPSGD  0.055586"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(results, orient=\"index\")\n",
    "df.index = pd.MultiIndex.from_tuples(df.index)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e992fb34-372a-458b-ae87-86c3c631e62d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">utkface</th>\n",
       "      <th>ERM</th>\n",
       "      <td>0.020405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DRO</th>\n",
       "      <td>0.060203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DRO wd</th>\n",
       "      <td>0.068113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERM IW</th>\n",
       "      <td>0.016250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERM DPSGD</th>\n",
       "      <td>0.026500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERM IW DPSGD</th>\n",
       "      <td>0.060824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DRO DPSGD</th>\n",
       "      <td>0.068309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0\n",
       "utkface ERM           0.020405\n",
       "        DRO           0.060203\n",
       "        DRO wd        0.068113\n",
       "        ERM IW        0.016250\n",
       "        ERM DPSGD     0.026500\n",
       "        ERM IW DPSGD  0.060824\n",
       "        DRO DPSGD     0.068309"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(results, orient=\"index\")\n",
    "df.index = pd.MultiIndex.from_tuples(df.index)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
